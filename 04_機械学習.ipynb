{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "04_機械学習.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Utree/MachineLearningSeminar/blob/master/04_%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oTT6K34XmFb1",
        "colab_type": "text"
      },
      "source": [
        "# はじめての機械学習\n",
        "\n",
        "アヤメのクラス分類アプリケーションを作ってみよう"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aho9Fbv8mPzn",
        "colab_type": "text"
      },
      "source": [
        "ある園芸家がアヤメの花の分類をしたいとする。\n",
        "\n",
        "彼女は花弁の長さと幅、がくの長さと幅をセンチメートル単位で測った。\n",
        "\n",
        "また、植物学者がsetosa, versicolor, virginicaに分類したアヤメの測定結果も持っており、このデータから園芸家が見つけたアヤメの種類を予測したいとする。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wI3KjDmGnHFc",
        "colab_type": "text"
      },
      "source": [
        "植物学者のデータはすでに種類がわかっている = 答え(教師データ)がわかっているので、教師あり学習と言える"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ztNMDwd2m7uX",
        "colab_type": "text"
      },
      "source": [
        "選択肢の中から一つ選ぶ = クラス分類(classification)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gkRhWwNDVvmd",
        "colab_type": "text"
      },
      "source": [
        "## データをインポート"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tT5OwH5mFKT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets import load_iris\n",
        "iris_dataset = load_iris()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JrkTb79MnXK7",
        "colab_type": "text"
      },
      "source": [
        "## データを見る"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2pIK-Vxls1T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# データの一覧\n",
        "print(\"Keys of iris_dataset: \\n{}\".format(iris_dataset.keys()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2uWoZfftV8yQ",
        "colab_type": "text"
      },
      "source": [
        "**DESCRキーにはデータセットの簡単な説明が書かれている**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ueQQH-Jvnqz9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# DESCRキーを表示\n",
        "print(iris_dataset['DESCR'][:193] + \"\\n...\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8aG7wK2RWfr3",
        "colab_type": "text"
      },
      "source": [
        "**target_namesキーには予測しようとしている花の種類が格納されている**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSzBqR9pn3AT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Target names: {}\".format(iris_dataset['target_names']))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3iZVYw0rWnp9",
        "colab_type": "text"
      },
      "source": [
        "**feature_namesキーには各特徴量の説明が書かれている**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Crg2qwMfoEGz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Feature names: \\n{}\".format(iris_dataset['feature_names']))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0gfCxujBWvFq",
        "colab_type": "text"
      },
      "source": [
        "**dataのデータ型はnumpy配列**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7MY1Ak_KoZTL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Type of data: {}\".format(type(iris_dataset['data'])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mggCFkiEW4OK",
        "colab_type": "text"
      },
      "source": [
        "**dataの形状は150x4**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BwZVBbBTofuA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Shape of data: {}\".format(iris_dataset['data'].shape))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jkLFYPOJXBNS",
        "colab_type": "text"
      },
      "source": [
        "**dataの中身を表示してみる**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3T23PC4eomDL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"First five columns of data: \\n{}\".format(iris_dataset['data'][:5]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99gjvfRlXAwL",
        "colab_type": "text"
      },
      "source": [
        "**targetのデータ型はnumpy配列**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygnQ-YyEos7A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Type of target: {}\".format(type(iris_dataset['target'])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRU7WLSYXUA-",
        "colab_type": "text"
      },
      "source": [
        "**targetの形状は150x1**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGhaH6xAo9Sg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Shape of target: {}\".format(iris_dataset['target'].shape))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ObYoabIuXYFL",
        "colab_type": "text"
      },
      "source": [
        "**targetの中身を表示してみる**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1AN_z8IMpFLi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Target:\\n{}\".format(iris_dataset['target']))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "60RZb9jIpnEQ",
        "colab_type": "text"
      },
      "source": [
        "**モデル** : 理想状態。現実の状態にモデルを近づけていき、モデルを利用することで、予測したり分類したりする。\n",
        "\n",
        "**汎化** : 未知の知らないデータに対してもモデルがうまく機能すること"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPByHIGkqW-m",
        "colab_type": "text"
      },
      "source": [
        "モデルの性能を評価するには、学習時とは別な新しいデータを使って評価する必要がある。\n",
        "\n",
        "この時、持っているすべてのデータを２つに分けて、一方を訓練データ(training data), もう一方をテストデータ(test data)と呼ぶ。\n",
        "\n",
        "training : test = 75 : 25とすることが一般？"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqMFJGmvXjl-",
        "colab_type": "text"
      },
      "source": [
        "## データをダウンロード"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sIBY_1blpPR-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "# データセットを分割, random_stateはランダムシードと呼ばれ、乱数生成時に用いる\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    iris_dataset['data'], iris_dataset['target'], random_state=0\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zxbYoApkXmwP",
        "colab_type": "text"
      },
      "source": [
        "## データの形状を表示"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4B8uyKQ3rcG0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"X_train shape: {}\".format(X_train.shape))\n",
        "print(\"y_train shape: {}\".format(y_train.shape))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Upv7DOdrxX8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"X_test shape: {}\".format(X_test.shape))\n",
        "print(\"y_test shape: {}\".format(y_test.shape))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pm-cWUZbsDzr",
        "colab_type": "text"
      },
      "source": [
        "## グラフ化してデータを見る"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBw6ZYXAuWSa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 著者自作のライブラリをインストール\n",
        "!pip install mglearn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zoKzDACr8nV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "from pandas.plotting import scatter_matrix\n",
        "import mglearn\n",
        "\n",
        "\n",
        "# X_trainのデータからDataFrameを作る\n",
        "# iris_dataset.feature_namesの文字列を使ってカラムに名前を付ける\n",
        "iris_dataframe = pd.DataFrame(X_train, columns=iris_dataset.feature_names)\n",
        "# データフレームからscatter matrixを作成し、y_trainに従って色を付ける\n",
        "grr = scatter_matrix(\n",
        "    iris_dataframe, c=y_train, figsize=(9, 9), marker='o', hist_kwds={'bins': 20},\n",
        "    s=60, alpha=.8, cmap=mglearn.cm3\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_bCJQa_YFeD",
        "colab_type": "text"
      },
      "source": [
        "## 花の種類を予測"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9QDEI3SEYPSg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# scikit-learnから機械学習用のライブラリインポート\n",
        "from sklearn.neighbors import KNeighborsClassifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yl50z_znswhs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# モデルを構築\n",
        "knn = KNeighborsClassifier(n_neighbors=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WbTLjshIuv-X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 学習\n",
        "knn.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Aac3eegZr9Z",
        "colab_type": "text"
      },
      "source": [
        "## 仮のデータをつくる"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YuFW_SoZuzk6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "# 仮のデータを作成\n",
        "X_new = np.array([[5, 2.9, 1, 0.2]])\n",
        "# 形状を表示\n",
        "print(\"X_new.shape: {}\".format(X_new.shape))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ejRb1A9RZue_",
        "colab_type": "text"
      },
      "source": [
        "## 予測 (仮データ)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gOVrg3Atu8-y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 予測\n",
        "prediction = knn.predict(X_new)\n",
        "\n",
        "\n",
        "# 推定\n",
        "print(\"Prediction: {}\".format(prediction))\n",
        "print(\"Predicted target name: {}\".format(iris_dataset['target_names'][prediction]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zWA87ohpZ9AK",
        "colab_type": "text"
      },
      "source": [
        "## 予測 (テストデータセット)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5bM4cngvMx2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = knn.predict(X_test)\n",
        "print(\"Test set precitions:\\n {}\".format(y_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YEMdKQkLaD79",
        "colab_type": "text"
      },
      "source": [
        "## テストの正答率"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-nUrEkWvV0O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Test set score: {:.2f}\".format(np.mean(y_pred == y_test)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_KIM0wSfvdVQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Test set score: {: .2f}\".format(knn.score(X_test, y_test)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aEdowgT5bFWa",
        "colab_type": "text"
      },
      "source": [
        "# 機械学習\n",
        "\n",
        "**テーマ**\n",
        "\n",
        "「機械学習」(Machine Learning: ML)\n",
        "\n",
        "**歴史**\n",
        "\n",
        "OCR(Optical Character Recognition: 光学的文字認識)では古くから使われている\n",
        "\n",
        "↓\n",
        "\n",
        "1990年代になってからスパムフィルタで使われるようになった\n",
        "\n",
        "↓\n",
        "\n",
        "おすすめ商品の提案、音声検索など数百以上のアプリケーションが開発される\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dcZtHRl5fav0",
        "colab_type": "text"
      },
      "source": [
        "## 機械学習って何?\n",
        "\n",
        "コンピュータがデータからアルゴリズムを構築するための学問分野"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xPrOZ8Lgfdi7",
        "colab_type": "text"
      },
      "source": [
        "## なぜ機械学習を使うの?\n",
        "\n",
        "以前は人間がルールベースにより手動でアルゴリズムを構築してきた\n",
        "\n",
        "↓\n",
        "\n",
        "手作業でルールを調整したり、そのルールが長くなったりする\n",
        "\n",
        "↓\n",
        "\n",
        "大変\n",
        "\n",
        "↓\n",
        "\n",
        "複雑な問題を、単純なコードで、高い精度で解決したい\n",
        "\n",
        "↓\n",
        "\n",
        "機械学習を使うモチベ：　データからアルゴリズムを**継続的**に**自動**で構築したい\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jAe9zBo3hpjx",
        "colab_type": "text"
      },
      "source": [
        "また、(アルゴリズムによって難易度は違うが)MLアルゴリズムを調べれば何を学習したのかが分かる\n",
        "\n",
        "↓\n",
        "\n",
        "MLから人が学ぶこともある\n",
        "\n",
        "↓\n",
        "\n",
        "このテクニックをデータマイニングと言う。\n",
        "\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mrQ3-UPmioiJ",
        "colab_type": "text"
      },
      "source": [
        "機械学習を使う理由\n",
        "- アルゴリズム構築の自動化\n",
        "- データから知見の獲得"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FuCUlt5HjNlC",
        "colab_type": "text"
      },
      "source": [
        "## 機械学習の種類\n",
        "\n",
        "1. 人間がどれだけ訓練に関わるか\n",
        "2. 訓練のタイミング\n",
        "3. 予測をする方法\n",
        "\n",
        "によって大きく分類できる"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xH2y27MS6q2W",
        "colab_type": "text"
      },
      "source": [
        "### 1. 人間が訓練にどれだけ関わるか\n",
        "\n",
        "機械学習では、訓練データをもとに学習をすすめるが、そのデータに人間がどれだけ手を加えているかで、機械学習の種類が分かれる\n",
        "\n",
        "1. 教師あり学習\n",
        "2. 教師なし学習\n",
        "3. 半教師あり学習\n",
        "4. 強化学習"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_gQU_1E7zCe",
        "colab_type": "text"
      },
      "source": [
        "#### 1-1 教師あり学習\n",
        "\n",
        "教師あり学習では、訓練データの中に**ラベル**と呼ばれる正解データが含まれる\n",
        "\n",
        "教師あり学習のタスクには**分類**と**回帰**がある\n",
        "\n",
        "##### 分類\n",
        "訓練データには、ラベルにクラス(離散値)が明示されており、分類方法を学習させるタスク\n",
        "\n",
        "##### 回帰\n",
        "訓練データには、ラベルには連続値が明示されており、数値を予測させるタスク\n",
        "\n",
        "\n",
        "##### 教師あり学習の種類\n",
        "- k近傍法\n",
        "- 線形回帰\n",
        "- ロジスティック回帰\n",
        "- サポートベクトルマシン(SVM)\n",
        "- 決定木\n",
        "- ニューラルネットワーク"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SyhwQ6iT-bxN",
        "colab_type": "text"
      },
      "source": [
        "#### 1-2 教師なし学習\n",
        "\n",
        "教師なし学習では、訓練データの中に**ラベル**と呼ばれる正解データは含まれていない\n",
        "\n",
        "##### 教師なし学習の種類\n",
        "- クラスタリング\n",
        "    - k平均\n",
        "    - 階層型クラスタ分析 (HCA)\n",
        "    - EMアルゴリズム (expectation maximization: 期待値最大化法)\n",
        "- 可視化と次元削減\n",
        "    - PCA (principal component analysis: 主成分分析)\n",
        "    - カーネルPCA\n",
        "    - LLE (Locally-Linear Embedding: 局所線形埋め込み)\n",
        "    - t-SNE(t-distributed stochastic neighbor embedding: t分布型確率的近傍埋め込み法)\n",
        "- 相関ルール学習\n",
        "    - アプリオリ\n",
        "    - eclat\n",
        "    \n",
        "##### クラスタリング\n",
        "似てる者同士のグループを見つけるタスク\n",
        "\n",
        "##### 可視化\n",
        "多次元のデータを与えると、2次元や3次元表現のデータを返し、データの構造を可視化をするタスク\n",
        "\n",
        "##### 次元削減\n",
        "関連性の高い類似のデータをまとめてデータの次元を減らすタスク\n",
        "\n",
        "##### 異常検知\n",
        "外れ値などの異常なデータを見つけるタスク\n",
        "\n",
        "##### 相関ルール学習\n",
        "大量のデータから関連性強いもの同士を見つけるタスク"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QqdnTMtBBqUQ",
        "colab_type": "text"
      },
      "source": [
        "#### 1-3半教師あり学習\n",
        "\n",
        "- 半教師あり学習では、訓練データの一部に**ラベル**と呼ばれる正解データは含まれている\n",
        "\n",
        "- ほとんどの半教師あり学習のアルゴリズムは、教師あり学習と教師なし学習を組み合わせたものである\n",
        "\n",
        "- 例) クラスタリングでグルーピングしてから、グループに対してラベル付けを行えば、すべてのデータにラベルを付けることができる。\n",
        "\n",
        "##### DBN(deep belief network)\n",
        "制限付きボルツマンマシン(restricted Boltzmann machines: RBM)という教師なし学習をした後に、教師あり学習アルゴルズムで微調整を行う\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZkFyqKvfDmsR",
        "colab_type": "text"
      },
      "source": [
        "#### 1-4 強化学習\n",
        "\n",
        "**エージェント(学習システム)**は環境を観察し、**方策**を元に行動選択をして、**報酬**または**ペナルティ**を受け取り、**方策**を更新するというアルゴリズム"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JWKY_oiGEjAR",
        "colab_type": "text"
      },
      "source": [
        "### 2. 訓練のタイミング\n",
        "\n",
        "機械学習では、訓練により学習(アルゴリズムを更新)していくが、訓練のタイミングによっても分類できる\n",
        "\n",
        "1. バッチ学習(オフライン学習)\n",
        "2. 差分学習(オンライン学習)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91sVhiZzFmLf",
        "colab_type": "text"
      },
      "source": [
        "#### 2-1 バッチ学習(オフライン学習)\n",
        "\n",
        "- バッチ学習では学習時にすべての訓練データを必要とする。\n",
        "- 新しい知識について学習させたい場合は、新データだけでなく元データを含めたすべてのデータを使って0から学習させなければいけない\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pb2CAz_4Gxys",
        "colab_type": "text"
      },
      "source": [
        "#### 2-1 差分学習(オンライン学習)\n",
        "\n",
        "- オンライン学習では1つづつ、あるいはミニバッチと言う小さなグループ単位で学習を進める\n",
        "- オンライン学習には**学習速度**と呼ばれる指標がある。学習速度が速ければシステムはすぐに新しいデータに対応可能で、学習速度が遅ければノイズなどに強くなる。\n",
        "- オンライン学習の問題点は不良なデータが与えられると、システムの精度が下がることである。そのため、入力をモニタリングして、異常検出が必要な場合もある。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6xRTPZiJLjX",
        "colab_type": "text"
      },
      "source": [
        "### 3. 予測をする方法\n",
        "\n",
        "#### 3-1 インスタンスベース学習\n",
        "既存のデータを丸暗記し、新しいデータに関しては、類似度を用いて、予測する\n",
        "\n",
        "#### 3-2 モデルベース学習\n",
        "データからモデル(理想状態)を構築し、モデルを使って予測する"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7QLNjtAjM9z",
        "colab_type": "text"
      },
      "source": [
        "## 機械学習の課題\n",
        "\n",
        "機械学習をする上で問題となるのは\n",
        "\n",
        "- 良くないアルゴリズム\n",
        "- 良くないデータ\n",
        "\n",
        "の2つが問題になる"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-aEbHY-kjcr8",
        "colab_type": "text"
      },
      "source": [
        "### 具体的な注意点\n",
        "\n",
        "- データの量が多いこと\n",
        "- 古いデータが新しいデータを代表する値になっていること\n",
        "    (小さなデータセットでは**サンプルノイズ**, 大きなデータセットでは**サンプリングバイアス**に注意しなければならない)\n",
        "- データに誤りや外れ値、ノイズ、欠損値が少ないこと\n",
        "- 訓練のために適切な特徴量を揃えること(**特徴量エンジニアリング**)\n",
        "    - **特徴量選択**: 特徴量を選ぶ\n",
        "    - **特徴量抽出**: 特徴量を組み合わせて作る\n",
        "- モデルを複雑にしすぎないこと(**過学習**: 訓練データに対して過度に適応してしまうこと　を起こし、汎化性能が下がる) \n",
        "    - **ハイパーパラメータ**によって、**正則化**(モデルに制限を与える)を行い、**自由度**をコントロールする\n",
        "- モデルを単純にしすぎないこと(**過小適合**: モデルが単純すぎて、予測しきれないこと　が起こる)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vFbbFaPabKKM",
        "colab_type": "text"
      },
      "source": [
        "## テストと検証\n",
        "機械学習モデルをどうやって客観的に評価するか？\n",
        "\n",
        "持っているデータを**トレーニング**と**テスト**に分割し、調べる\n",
        "\n",
        "↓\n",
        "\n",
        "**テスト**で調べた結果を考慮しチューニングを行って、再度**トレーニング**する\n",
        "\n",
        "↓\n",
        "\n",
        "間接的に**テスト**に対して過学習してしまい、本番稼働での汎化性能が下がる\n",
        "\n",
        "↓\n",
        "\n",
        "**トレーニング**, **テスト**, **バリデーション**の3分割をする。そして、原則として**テスト**を行うのは最後の1回のみとする"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rTfGdOisbJ37",
        "colab_type": "text"
      },
      "source": [
        "# オープンデータセットの一覧\n",
        "\n",
        "- [カリフォルニア大学アーバイン校MLリポジトリ](http://archive.ics.uci.edu/ml/)\n",
        "- [Kaggleデータセット](https://www.kaggle.com/datasets)\n",
        "- [Amazon AWSデータセット](http://aws.amazon.com/fr/datasets/)\n",
        "- [http://dataportals.org/](http://dataportals.org/)\n",
        "- [http://opendatamonitor.eu/](http://opendatamonitor.eu/)\n",
        "- [http://quandl.com/](http://quandl.com/)\n",
        "- [WikipediaのMLデータセットリスト](https://en.wikipedia.org/wiki/List_of_datasets_for_machine-learning_research)\n",
        "- [Quora.comの質問に対する解答](https://www.quora.com/Where-can-I-find-large-datasets-open-to-the-public)\n",
        "- [redditのデータセット](https://www.reddit.com/r/datasets/)\n",
        "- [Googleの画像データセット](https://storage.googleapis.com/openimages/web/index.html)\n",
        "- [動物の顔の写真](https://x6ud.github.io/#/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wWXEMeOY07tQ",
        "colab_type": "text"
      },
      "source": [
        "# 機械学習プロジェクトを体験してみよう\n",
        "\n",
        "データサイエンティストになったつもりで、プロジェクトを体験してみよう\n",
        "\n",
        "1. 問題の全体像を把握しよう\n",
        "2. データを手に入れよう\n",
        "3. 大切そうなデータを見つけ、可視化しよう\n",
        "4. 機械学習を行いやすいようにデータを準備しよう\n",
        "5. モデルを訓練しよう\n",
        "6. モデルを微調整しよう\n",
        "7. プレゼンをしよう\n",
        "8. 本番稼働、モニタリング、メンテナンスしてみよう"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EB1yNs3jHkY0",
        "colab_type": "text"
      },
      "source": [
        "StatLibリポジトリから1990年のカリフォルニアの住宅価格データセットを使う\n",
        "\n",
        "なおこのデータセットはカリフォルニア州の調査帰ら得られたデータである"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Srs96t9ZH4Bx",
        "colab_type": "text"
      },
      "source": [
        "## 1. 問題の全体像を把握しよう\n",
        "\n",
        "### 問題設定\n",
        "\n",
        "- あなたがこれから行う仕事は、カリフォルニア州の国勢調査データを使ってカリフォルニアの住宅価格のモデルを作ることである。\n",
        "- このデータにはカリフォルニア州の各国勢調査細分区グループの人口、収入の中央値、住宅価格の中央値といった指標が含まれている\n",
        "- 細分区グループとは合衆国国勢調査局が定めた最小の地理的単位で、1細分区グループには600-3000人の人口がある\n",
        "- これから細分区グループのことを区域と呼ぶ\n",
        "- あなたはこのデータを使って学習し、他のすべての指標から任意の区域の住宅価格の中央値を予測できなければならない\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJ4hlqcvJQ_4",
        "colab_type": "text"
      },
      "source": [
        "### ビジネスサイドの目標は何か?\n",
        "\n",
        "おそらくモデルを作ることは最終的な目標ではない。\n",
        "\n",
        "まず、モデルを\n",
        "- **「どのように使って」**\n",
        "- **「何を得たいのか」**\n",
        "\n",
        "を知る必要がある。なぜなら、今後選択する以下の項目の判断基準になるからだ\n",
        "\n",
        "- 「問題をどのように組み立てるのか」\n",
        "- 「どのアルゴリズムを選ぶか」\n",
        "- 「モデルの評価にどのような性能指標を使うか」\n",
        "- 「どのくらい労力をかけるべきか」\n",
        "\n",
        "上司に尋ねた結果、このモデルの出力は他のシグナル(情報)とセットにして、他の機械学習システムに与え、最終的には、投資の価値判断を行うそうだ。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oHJ24JoDLxgU",
        "colab_type": "text"
      },
      "source": [
        "**パイプライン**\n",
        ": データ処理コンポーネントをつなげたものをデータ**パイプライン**と呼ぶ。機械学習システムでは、操作するデータが大量にあり、行わなければならないデータ変換もたくさんあるので、パイプラインが作られることが非常に多い。\n",
        "\n",
        "コンポーネントは一般的に非同期的に実行されており、個々のコンポーネントは自己完結的になっている。こうすることで複数のチームが別々のコンポーネントに専念できる。また、1つのコンポーネントが壊れたとしても、最後に出力したデータを使って、実行を続けられるので、アーキテクチャとして堅牢になる\n",
        "\n",
        "しかし、障害を起こしたことに気づきにくくなるので、モニタリングをしなければならない"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CtEXElSPNFgh",
        "colab_type": "text"
      },
      "source": [
        "次に知るべきことは、**現在のソリューション**がどのようなものかだ。既存ソリューションは性能の比較対象になることが多く、問題解決のヒントが得られることも多い。\n",
        "\n",
        "\n",
        "上司に尋ねた結果、区域の住宅価格は専門家がマニュアルで推計しているそうだ。この方法は住宅価格の中央値を集められない時、区域の最新情報を集め、複雑な規則を使って推計値を導いているが、時間とコストがかかる上に、推計結果はそれほど良くない(この推定は実際の中央値と10%以上も離れている事がある。これは区域に関する他のデータを考慮し推定しているためである)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fmj0JCoZOMY0",
        "colab_type": "text"
      },
      "source": [
        "**モデルを作る目的**と**現在のソリューション**の2つが分かれば、システム設計に取り掛かれる。まずは、\n",
        "\n",
        "- 教師あり学習/教師なし学習/強化学習\n",
        "- 分類/回帰/その他のタスク\n",
        "- バッチ学習/オンライン学習\n",
        "\n",
        "から選んでいく。\n",
        "\n",
        "\n",
        "- ラベル付きの訓練データが与えられているので、**教師あり学習**である。\n",
        "- また、複数の特徴量をを使って値を予測するので**多変量回帰**問題である\n",
        "- システムに継続的にデータが届くわけではないので、**バッチ学習**を行う"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oyjQglIwTgfB",
        "colab_type": "text"
      },
      "source": [
        "### 性能指標を選択する\n",
        "\n",
        "回帰問題の典型的な性能指標は平均二乗誤差(Root Mean Square Error: RMSE)である。\n",
        "\n",
        "どの程度の誤差がシステムの予測に含まれているのかを示す指標"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61jyn-TuaCBM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%html\n",
        "<script type=\"text/javascript\" src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax\n",
        "/2.7.0/MathJax.js?config=TeX-AMS_CHTML\"></script>\n",
        "<body>\n",
        "\\[\n",
        "RMSE(X, h) = \\sqrt{ \\frac{1}{m} \\sum_{i=1}^{m} (h(x^{(i)}) - y^{(i)})^2}\n",
        "\\]\n",
        "</body>"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TvK9za2eAfPP",
        "colab_type": "text"
      },
      "source": [
        "**記法**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P329Rem3_8oH",
        "colab_type": "text"
      },
      "source": [
        "- m: データセットのインスタンス(フィールド)数"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6cw5z2CPAkkN",
        "colab_type": "text"
      },
      "source": [
        "- x^{(i)}はデータセットのi番目のインスタンスに含まれるすべての特徴量(ラベルを除く)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2uuR2SZ14dsR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%html\n",
        "<script type=\"text/javascript\" src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax\n",
        "/2.7.0/MathJax.js?config=TeX-AMS_CHTML\"></script>\n",
        "<body>\n",
        "\\[\n",
        "\\begin{equation}\n",
        "x^{(1)} = \n",
        "\\begin{pmatrix}\n",
        "-118.29 \\\\\n",
        "33.91 \\\\\n",
        "1.416 \\\\\n",
        "38.372\n",
        "\\end{pmatrix}\n",
        "\\end{equation}\n",
        "\\]\n",
        "</body>"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63o7zWxmAmzU",
        "colab_type": "text"
      },
      "source": [
        "- y^{(i)}はi番目のインスタンスのラベル"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPZNRwJu4n6r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%html\n",
        "<script type=\"text/javascript\" src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax\n",
        "/2.7.0/MathJax.js?config=TeX-AMS_CHTML\"></script>\n",
        "<body>\n",
        "\\[\n",
        "y^{(1)} = 156.400\n",
        "\\]\n",
        "</body>"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kcmHwPF8At0B",
        "colab_type": "text"
      },
      "source": [
        "- Xはデータセットのすべての特徴量(ラベルを除く)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JOWwj3166LnV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%html\n",
        "<script type=\"text/javascript\" src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax\n",
        "/2.7.0/MathJax.js?config=TeX-AMS_CHTML\"></script>\n",
        "<body>\n",
        "\\[\n",
        "\\begin{equation}\n",
        "X = \n",
        "\\begin{pmatrix}\n",
        "(x^{(1)})^{T} \\\\\n",
        "(x^{(2)})^{T} \\\\\n",
        "\\vdots \\\\\n",
        "(x^{(1999)})^{T} \\\\\n",
        "(x^{(2000)})^{T} \\\\\n",
        "\\end{pmatrix}\n",
        "=\n",
        "\\begin{pmatrix}\n",
        "-118.29 &33.91 &1.416 &38.372 \\\\\n",
        "\\vdots &\\vdots &\\vdots &\\vdots\n",
        "\\end{pmatrix}\n",
        "\\end{equation}\n",
        "\\]\n",
        "</body>"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BLHG5xEPA-XW",
        "colab_type": "text"
      },
      "source": [
        "- hはシステムの予測関数で**仮説**とも呼ばれる\n",
        "\n",
        "システムにインスタンスの特徴量ベクトルx^(i)を与えると、システムはインスタンスの予測値yハット = h(x^(i))を返す"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ke-af3ueCYyV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%html\n",
        "<script type=\"text/javascript\" src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax\n",
        "/2.7.0/MathJax.js?config=TeX-AMS_CHTML\"></script>\n",
        "<body>\n",
        "\\[\n",
        "\\hat{y} = h(x^{(i)})\n",
        "\\]\n",
        "</body>"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40fxk5v3CjnK",
        "colab_type": "text"
      },
      "source": [
        "回帰の性能指標としては一般にRMSEが望ましいものとされているが、他の関数を使ったほうが良い場合もある。たとえば外れ値となる区域が多数ある場合、平均絶対誤差, 平均絶対偏差(mean absolute error: MAE)を使うとよい"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qB5vXjw-8Pt4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%html\n",
        "<script type=\"text/javascript\" src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax\n",
        "/2.7.0/MathJax.js?config=TeX-AMS_CHTML\"></script>\n",
        "<body>\n",
        "\\[\n",
        "MAE(X, h) = \n",
        "\\frac{1}{m} \n",
        "\\sum_{i=1}^{m}\n",
        "\\left|\n",
        "h(x^{(i)}) - y^{(i)}\n",
        "\\right|\n",
        "\\]\n",
        "</body>"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zO7WAXQuC-x6",
        "colab_type": "text"
      },
      "source": [
        "RMSEとMAEはどちらもふたつのベクトルの距離を測定する方法である。\n",
        "\n",
        "距離の指標のことを**ノルム**という\n",
        "\n",
        "- 誤差の二乗の総和の平方根(RMSE)は**ユークリッドノルム(Euclidian norm)**に対応しており、L2ノルムとも呼ばれ、||・||2や||・||と表記される\n",
        "- 誤差の絶対値の総和(MAE)はL1ノルムで||・||1と表記される。　また**マンハッタンノルム**とも呼ばれる"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8XAi6a1G5nF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%html\n",
        "<script type=\"text/javascript\" src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax\n",
        "/2.7.0/MathJax.js?config=TeX-AMS_CHTML\"></script>\n",
        "<body>\n",
        "\\[\n",
        "n個の要素を含むベクトルvのl_{k}ノルムは \\\\\n",
        "\n",
        "\\|v\\|_{k} = \n",
        "( \\left| v_0 \\right|^{k} + \\left| v_1 \\right|^{k} + \\cdots + \\left| v_n \\right|^{k})^{ \\frac{1}{k} } \\cdot l_0 \\\\\n",
        "\n",
        "ここで、l_0はベクトルの非ゼロの要素の数を表す\n",
        "\\]\n",
        "</body>"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hs9HhZ6HHGeN",
        "colab_type": "text"
      },
      "source": [
        "- ノルムの添字が大きくなればなるほど、大きな値を重視し、小さな値を無視する方向に傾く。\n",
        "- RMSEがMAEよりも外れ値の影響を受けやすい\n",
        "- 外れ値が指数的に減少するときは、RMSEは高い性能を発揮する"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TCT2BYYMIDze",
        "colab_type": "text"
      },
      "source": [
        "### 前提条件をチェックする\n",
        "\n",
        "最後に問題の全体像をリストアップし、まとめる\n",
        "\n",
        "たとえば、私達のモデルがつくる住宅価格のデータを下流の機械学習システムが、(低、中、高)のカテゴリに変換する場合、正しい価格を計算することが求められていないということが分かる"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OaE8UO3XI0H-",
        "colab_type": "text"
      },
      "source": [
        "## 2. データを手に入れる"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V8RxammOJCwl",
        "colab_type": "text"
      },
      "source": [
        "### データをダウンロードする\n",
        "\n",
        "データをダウンロードするための関数を作るほうが望ましい"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JnPRsTkdJG4W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import tarfile\n",
        "from six.moves import urllib\n",
        "\n",
        "DOWNLOAD_ROOT = \"https://raw.githubusercontent.com/ageron/handson-ml/master/\"\n",
        "HOUSING_PATH = os.path.join(\"datasets\", \"housing\")\n",
        "HOUSING_URL = DOWNLOAD_ROOT + \"datasets/housing/housing.tgz\"\n",
        "\n",
        "# ダウンロード用のモジュール\n",
        "def fetch_housing_data(housing_url=HOUSING_URL, housing_path=HOUSING_PATH):\n",
        "    # パスの確認\n",
        "    if not os.path.isdir(housing_path):\n",
        "        os.makedirs(housing_path)\n",
        "    # ダウンロード先の設定\n",
        "    tgz_path = os.path.join(housing_path, \"housing.tgz\")\n",
        "    # ダウンロード\n",
        "    urllib.request.urlretrieve(housing_url, tgz_path)\n",
        "    # 解凍\n",
        "    housing_tgz = tarfile.open(tgz_path)\n",
        "    housing_tgz.extractall(path=housing_path)\n",
        "    housing_tgz.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1U3XXnMPLkIj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ダウンロード\n",
        "fetch_housing_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Nxm7XWqLLxM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# CSVの読み込み用モジュール\n",
        "# csvファイルからpandasのデータフレームオブジェクトへ変換する\n",
        "def load_housing_data(housing_path=HOUSING_PATH):\n",
        "    csv_path = os.path.join(housing_path, \"housing.csv\")\n",
        "    return pd.read_csv(csv_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TMulNfLNYYl_",
        "colab_type": "text"
      },
      "source": [
        "### データの構造をざっと見てみる"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLZGI4TGLaGI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# csvを読み込んで表示\n",
        "housing = load_housing_data()\n",
        "housing.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "meLFYLbbMOcb",
        "colab_type": "text"
      },
      "source": [
        "| カラム名               |  説明       | \n",
        "|--------------------|-----------| \n",
        "| longitude          |  経度       | \n",
        "| latitude           |  緯度       | \n",
        "| housing_median_age |  築年数の中央値  | \n",
        "| total_rooms        |  部屋数      | \n",
        "| total_bedrooms     |  寝室数      | \n",
        "| population         |  人口       | \n",
        "| households         |  世帯数      | \n",
        "| median_income      |  収入の中央値   | \n",
        "| median_house_value |  住宅価格の中央値 | \n",
        "| ocean_proximity    |  海との位置関係  | \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h3mGLScBMOD-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# データについての情報\n",
        "# データ型やnullでないデータの数がどれだけあるかなどの情報を見ることができる\n",
        "housing.info()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ne0vrWPoMJkq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ocean_proximityカラムに含まれる値の種類とその数\n",
        "housing[\"ocean_proximity\"].value_counts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hd4u4BhvN3do",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 数値属性の集計情報\n",
        "# null以外を対象にしており、個数、平均値、標準偏差、最大値、第N四分位数\n",
        "housing.describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vDjvj9axPBwS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ヒストグラムを表示する\n",
        "housing.hist(bins=50, figsize=(20, 15))\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gl8KBe2OQC9U",
        "colab_type": "text"
      },
      "source": [
        "### ヒストグラムから気づくこと\n",
        "\n",
        "- 収入の中央値(median_income)は米ドルで表現されていない。　値をスケーリングした上で上限を15.0001, 下限を0.4999に切っている。　機械学習では前処理済みの値を使うことは普通であり、必ずしも問題にはならないが、データがどのように計算されたかは理解しておくようにしたい\n",
        "- 築年数の中央値と住宅価格の中央値も上限を切ってある。後者はターゲット属性(ラベル)なので、非常に重要な問題である。これが問題かどうかはクライアントチーム(あなたのシステムの出力を行うチーム)と協力してチェックする必要がある。50万ドルを超えても正確な予測が必要である場合の選択肢は以下の2つである\n",
        "    - 上限を超えている区域の正しいラベルを集める\n",
        "    - 訓練セットからそれらの区域を取り除く(50万ドルを超える値を予測した時にシステムの評価が下がるので、テストセットからも取り除く)\n",
        "- 多くのヒストグラムが**テールヘビー**：左側よりも右側が大きく広がっている。このような形になっていると一部の機械学習アルゴリズムはパターンを見つけにくくなることがあるので、そういった属性に関しては後で、ベル型の分布に近づくように変換する"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yN7GwkMkSQ2L",
        "colab_type": "text"
      },
      "source": [
        "### ランダムサンプリング(テストセットを作る)\n",
        "**データスヌーピングバイアス**(data snooping bias: データを盗み見る事によって入ってしまう偏見)を避けるために、この段階でトレーニングとテストデータセットに分けてしまう。\n",
        "\n",
        "これはどのアルゴリズムを使うべきかを決める前にデータについて知りすぎると、人間が無意識のうちにパターン認識をしてしまい、過学習してしまうことがあるため。\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RhD0PkUBUGuu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# データセットを分ける関数\n",
        "def split_train_test(data, test_raito):\n",
        "    shuffled_indices = np.random.permutation(len(data))\n",
        "    test_set_size = int(len(data) * test_raito)\n",
        "    test_indices = shuffled_indices[:test_set_size]\n",
        "    train_indices = shuffled_indices[test_set_size:]\n",
        "    return data.iloc[train_indices], data.iloc[test_indices]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1DFYj9uUimG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# データセットを分割\n",
        "train_set, test_set = split_train_test(housing, 0.2)\n",
        "\n",
        "# 表示\n",
        "print(len(train_set), \"train + \", len(test_set), \"test\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7U4zp-JpaYcg",
        "colab_type": "text"
      },
      "source": [
        "最初の実行時に使ったテストセットを保存し、その後の実行時にも同じテストセットをロードしたい。\n",
        "\n",
        "各データの識別子を使って、そのデータセットがテストセットに属するべきものかどうかを判断する方法がある。\n",
        "\n",
        "各データの識別子のハッシュ値を計算し、ハッシュの最後のバイトだけを保存して、この値が51(=256\\*0.2: テスト比)以下ならテストセットに送る\n",
        "\n",
        "こうすればデータセットをリフレッシュしても、テストセットの作成関数は複数実行されても一定に保たれる。\n",
        "\n",
        "新しいテストセットには新しいインスタンスの20%が含まれるが、以前、訓練セットに含まれていたデータは一切入らない。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_kJpzU6PTR-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import hashlib\n",
        "\n",
        "# ハッシュ値を見てふるい分けする関数\n",
        "def test_set_check(identifier, test_ratio, hash):\n",
        "    return hash(np.int64(identifier)).digest()[-1] < 256 * test_ratio\n",
        "\n",
        "# データセットを分ける関数\n",
        "def split_train_test_by_id(data, test_ratio, id_column, hash=hashlib.md5):\n",
        "    ids = data[id_column]\n",
        "    in_test_set = ids.apply(lambda id_: test_set_check(id_, test_ratio, hash))\n",
        "    return data.loc[~in_test_set], data.loc[in_test_set]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tnjt_LvkQSeB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# idカラムを作成\n",
        "housing_with_id = housing.reset_index() # ID列を追加する\n",
        "# データセットを分ける\n",
        "train_set, test_set = split_train_test_by_id(housing_with_id, 0.2, \"index\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zEC6dnGLQi26",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 緯度、経度からidカラムをつくる\n",
        "housing_with_id[\"id\"] = housing[\"longitude\"] * 1000 + housing[\"latitude\"]\n",
        "# データセットを分ける\n",
        "train_set, test_set = split_train_test_by_id(housing_with_id, 0.2, \"id\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOzk-rSgQ5ZV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# scikit-learnにもデータセット分割用のメソッドが実装されている\n",
        "# 上で実装した関数よりすこし高機能\n",
        "train_set, test_set = train_test_split(housing, test_size=0.2, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tBPy4Fw1gD5x",
        "colab_type": "text"
      },
      "source": [
        "### ストラティファイドサンプリング: 層化抽出法 (テストセットをつくる)\n",
        "\n",
        "上の方法ではサンプリングバイアスを持ち込んでしまう可能性がある。\n",
        "\n",
        "サンプリングバイアス: 不適切な標本抽出によって、母集団を代表しない特定の性質のデータがまぎれこむこと\n",
        "\n",
        "そのためたとえば、男女比が7:3のとき、サンプルでも7:3の比率を守って抽出する。\n",
        "\n",
        "これを**層化抽出法(stratified sampling)**という。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7oB2InOBhbiW",
        "colab_type": "text"
      },
      "source": [
        "専門家から、収入の中央値(median_income)カラムは住宅価格の中央値を予測する上で重要な属性だといわれたとする。\n",
        "\n",
        "そこで、収入の中央値(median_income)カラムを使って、カテゴリ変数を作る。\n",
        "\n",
        "ここでは\n",
        "0.499900〜15.000100の値を等間隔で2/3分割し、ある一定数以上であれば、1つにまとめてしまう\n",
        "という手順を用いて作っている"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oU8pXPl2mXfe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "housing[\"median_income\"].hist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zm3rDUJnRGQn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 2/3分割する\n",
        "housing[\"income_cat\"] = np.ceil(housing[\"median_income\"] / 1.5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMw5HFypmj_k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "housing[\"income_cat\"].hist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33_7bwHpmjbr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 5以上の値をひとまとめにする\n",
        "housing[\"income_cat\"].where(housing[\"income_cat\"] < 5, 5.0, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZ9FU3NVmcJH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "housing[\"income_cat\"].hist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7Y7q-hsRWG5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "# scikit-learnのStratifiedShuffleSplitを使って層化抽出を行う\n",
        "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
        "for train_index, test_index in split.split(housing, housing[\"income_cat\"]):\n",
        "    strat_train_set = housing.loc[train_index]\n",
        "    strat_test_set = housing.loc[test_index]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49H8PfM8mVxm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "strat_train_set[\"income_cat\"].hist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E1OLui8ZmNcF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "strat_test_set[\"income_cat\"].hist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRpECb0um5Oh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 各抽出方法の誤差率を算出する\n",
        "def income_cat_proportions(data):\n",
        "    return data[\"income_cat\"].value_counts() / len(data)\n",
        "\n",
        "train_set, test_set = train_test_split(housing, test_size=0.2, random_state=42)\n",
        "\n",
        "compare_props = pd.DataFrame({\n",
        "    \"Overall\": income_cat_proportions(housing),\n",
        "    \"Stratified\": income_cat_proportions(strat_test_set),\n",
        "    \"Random\": income_cat_proportions(test_set),\n",
        "}).sort_index()\n",
        "compare_props[\"Rand. %error\"] = 100 * compare_props[\"Random\"] / compare_props[\"Overall\"] - 100\n",
        "compare_props[\"Strat. %error\"] = 100 * compare_props[\"Stratified\"] / compare_props[\"Overall\"] - 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTF28YaIm8YV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 無作為誤差率と層化抽出誤差率\n",
        "compare_props"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKj3iSOXfgeE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# income_cat属性を取り除いてデータを元の状態に戻す\n",
        "for set_ in (strat_train_set, strat_test_set):\n",
        "    set_.drop(\"income_cat\", axis=1, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HH_6N5LIiL2F",
        "colab_type": "text"
      },
      "source": [
        "## 3. 大切そうなデータを見つけ、可視化しよう"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iI5CuVV7fyjU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# バックアップ用にコピーをとる\n",
        "housing = strat_train_set.copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yW3_RsZiUyU",
        "colab_type": "text"
      },
      "source": [
        "### 地理データの可視化"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9EXKuXfCf2eX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 散布図を書く\n",
        "housing.plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GoSN2cN2gBWI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 密度を可視化するべく、透明度を設定する\n",
        "housing.plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\", alpha=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evKTSPIigPqu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 住宅価格を可視化するべく、半径を人口、価格をヒートマップの色、透明度で密度を設定する\n",
        "housing.plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\", alpha=0.4,\n",
        "            s=housing[\"population\"]/100, label=\"population\", figsize=(10, 7),\n",
        "            c=\"median_house_value\", cmap=plt.get_cmap(\"jet\"), colorbar=True)\n",
        "\n",
        "plt.legend()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ogubTghioXzZ",
        "colab_type": "text"
      },
      "source": [
        "この散布図からは、海の近くや人口密度が住宅価格に大きな影響を及ぼしていることがわかる"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8urCH4ciZzz",
        "colab_type": "text"
      },
      "source": [
        "### 相関を探す"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMwEU9qfg6wK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corr_matrix = housing.corr()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rf7bUrMng-7H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corr_matrix[\"median_house_value\"].sort_values(ascending=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vVW6KK_hIQ9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pandas.plotting import scatter_matrix\n",
        "\n",
        "attributes = [\"median_house_value\", \"median_income\", \"total_rooms\", \"housing_median_age\"]\n",
        "scatter_matrix(housing[attributes], figsize=(12, 8))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4iRT7_Zhfso",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "housing.plot(kind=\"scatter\", x=\"median_income\", y=\"median_house_value\", alpha=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJOlbiNhUGRy",
        "colab_type": "text"
      },
      "source": [
        "### 属性の組み合わせを試す"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5paM1Nminxj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "housing[\"rooms_per_household\"] = housing[\"total_rooms\"] / housing[\"households\"]\n",
        "housing[\"bedrooms_per_room\"] = housing[\"total_bedrooms\"] / housing[\"total_rooms\"]\n",
        "housing[\"population_per_household\"] = housing[\"population\"] / housing[\"households\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DclcwQwxjE7C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corr_matrix = housing.corr()\n",
        "corr_matrix[\"median_house_value\"].sort_values(ascending=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0LJ0IEvjVxM",
        "colab_type": "text"
      },
      "source": [
        "## 4. 機械学習を行いやすいようにデータを準備しよう"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1aInG3AjVXq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "housing = strat_train_set.drop(\"median_house_value\", axis=1)\n",
        "housing_labels = strat_train_set[\"median_house_value\"].copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhHImVnOkcS9",
        "colab_type": "text"
      },
      "source": [
        "### データをクリーニングする"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHZwnVzakhw4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "housing.dropna(subset=[\"total_bedrooms\"]) # オプション1\n",
        "housing.drop(\"total_bedrooms\", axis=1)       # オプション2\n",
        "median = housing[\"total_bedrooms\"].median() # オプション3\n",
        "housing[\"total_bedrooms\"].fillna(median, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9K9Pc7tJlEBg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import Imputer\n",
        "\n",
        "imputer = Imputer(strategy=\"median\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjqG1bkGlM6T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "housing_num = housing.drop(\"ocean_proximity\", axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zuedoNURlVhN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "imputer.fit(housing_num)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eo8NRKMTlaDY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "imputer.statistics_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBn5y9qClmmM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "housing_num.median().values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NIF2hm34lrSz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = imputer.transform(housing_num)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGrTYetXlvI9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "housing_tr = pd.DataFrame(X, columns=housing_num.columns)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LVPHoSP-l-Zy",
        "colab_type": "text"
      },
      "source": [
        "### テキスト/カテゴリ属性の処理"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dq-7KogWl6Dx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "housing_cat = housing[\"ocean_proximity\"]\n",
        "housing_cat.head(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2Y99wHRmMac",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "housing_cat_encoded, housing_categories = housing_cat.factorize()\n",
        "housing_cat_encoded[:10]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKpNXIeGmW76",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "housing_categories"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0c-iNU9mZi5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "encoder = OneHotEncoder()\n",
        "housing_cat_1hot = encoder.fit_transform(housing_cat_encoded.reshape(-1, 1))\n",
        "housing_cat_1hot"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3no9VUYm4Pg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "housing_cat_1hot.toarray()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7F2YenBbaH9A",
        "colab_type": "text"
      },
      "source": [
        "### カスタム変換"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2sLSIJLAd0S9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip freeze | grep sklearn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCPYcFLlm33p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "rooms_ix, bedrooms_ix, population_ix, household_ix = 3, 4, 5, 6\n",
        "\n",
        "class CombinedAttributesAdder(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, add_bedrooms_per_room = True): # *args, **kargsなし\n",
        "        self.add_bedrooms_per_room = add_bedrooms_per_room\n",
        "    def fit(self, X, y=None):\n",
        "        return self # ほかにすることなし\n",
        "    def transform(self, X, y=None):\n",
        "        rooms_per_household = X[:, rooms_ix] / X[:, household_ix]\n",
        "        population_per_household = X[:, population_ix] / X[:, household_ix]\n",
        "        if self.add_bedrooms_per_room:\n",
        "            bedrooms_per_room = X[:, bedrooms_ix] / X[:, rooms_ix]\n",
        "            return np.c_[X, rooms_per_household, population_per_household, bedrooms_per_room]\n",
        "        else:\n",
        "            return np.c_[X, rooms_per_household, population_per_household]\n",
        "\n",
        "attr_adder = CombinedAttributesAdder(add_bedrooms_per_room=False)\n",
        "housing_extra_attribs = attr_adder.transform(housing.values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dPucbWHnZ_tc",
        "colab_type": "text"
      },
      "source": [
        "### 変換パイプライン"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kUx0yEfym3zx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "num_pipeline = Pipeline([\n",
        "    ('imputer', Imputer(strategy=\"median\")),\n",
        "    ('attribs_adder', CombinedAttributesAdder()),\n",
        "    ('std_scaler', StandardScaler()),\n",
        "])\n",
        "\n",
        "housing_num_tr = num_pipeline.fit_transform(housing_num)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-z2yGh3um3x-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "class DataFrameSelector(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, attribute_names):\n",
        "        self.attribute_names = attribute_names\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "    def transform(self, X):\n",
        "        return X[self.attribute_names].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tlZp5o1Em3u9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_attribs = list(housing_num)\n",
        "cat_attribs = [\"ocean_proximity\"]\n",
        "\n",
        "num_pipeline = Pipeline([\n",
        "    ('selector', DataFrameSelector(num_attribs)),\n",
        "    ('imputer', Imputer(strategy=\"median\")),\n",
        "    ('attribs_adder', CombinedAttributesAdder()),\n",
        "    ('std_scaler', StandardScaler()),\n",
        "])\n",
        "\n",
        "cat_pipeline = Pipeline([\n",
        "    ('selector', DataFrameSelector(cat_attribs)),\n",
        "    ('cat_encoder', OneHotEncoder()),\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2hgRidTVm3r3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.pipeline import FeatureUnion\n",
        "\n",
        "full_pipeline = FeatureUnion(transformer_list=[\n",
        "    (\"num_pipeline\", num_pipeline),\n",
        "    (\"cat_pipeline\", cat_pipeline),\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUAjEPp_m3ih",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "housing_prepared = full_pipeline.fit_transform(housing)\n",
        "housing_prepared"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mfAoH1xKvZh5",
        "colab_type": "text"
      },
      "source": [
        "## モデルを選択して訓練する"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yqMw_EMrvchl",
        "colab_type": "text"
      },
      "source": [
        "## 訓練セットを訓練、評価する"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mcX9OJ4VaSK3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "lin_reg = LinearRegression()\n",
        "lin_reg.fit(housing_prepared, housing_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sEzzvLIUaSIe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "some_data = housing.iloc[:5]\n",
        "some_labels = housing_labels.iloc[:5]\n",
        "some_data_prepared = full_pipeline.transform(some_data)\n",
        "print(\"Predictions:\", lin_reg.predict(some_data_prepared))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uV0u9nrfaSF7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Labels:\", list(some_labels))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iI9sTZSjaSCy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "housing_predictions = lin_reg.predict(housing_prepared)\n",
        "lin_mse = mean_squared_error(housing_labels, housing_predictions)\n",
        "lin_rmse = np.sqrt(lin_mse)\n",
        "lin_rmse"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xwfh2ri6aR-y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "tree_reg = DecisionTreeRegressor()\n",
        "tree_reg.fit(housing_prepared, housing_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-MsL8MmaR7Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "housing_predictions = tree_reg.predict(housing_prepared)\n",
        "tree_mse = mean_squared_error(housing_labels, housing_predictions)\n",
        "tree_rmse = np.sqrt(tree_mse)\n",
        "tree_rmse"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Geo9Km87yWYA",
        "colab_type": "text"
      },
      "source": [
        "## 交差誤差検証を使ったよりよい評価"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4KxgHgfAaR14",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "scores = cross_val_score(tree_reg, housing_prepared, housing_labels, scoring=\"neg_mean_squared_error\", cv=10)\n",
        "tree_rmse_scores = np.sqrt(-scores)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5w_pLA61aRyG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def display_scores(scores):\n",
        "    print(\"Scores:\", scores)\n",
        "    print(\"Mean:\", scores.mean())\n",
        "    print(\"Standard deviation:\", scores.std())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWv63utTzRzo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "display_scores(tree_rmse_scores)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QVwZH2-vzRuL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lin_scores = cross_val_score(lin_reg, housing_prepared, housing_labels,\n",
        "                            scoring=\"neg_mean_squared_error\", cv=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nwd_ONfdzRrt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lin_rmse_scores = np.sqrt(-lin_scores)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66K-gVHCzReN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "display_scores(lin_rmse_scores)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0HF7tV00yaN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "forest_reg = RandomForestRegressor()\n",
        "forest_reg.fit(housing_prepared, housing_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6j_b3Fi63AKS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "housing_predictions = forest_reg.predict(housing_prepared)\n",
        "forest_mse = mean_squared_error(housing_labels, housing_predictions)\n",
        "forest_rmse = np.sqrt(forest_mse)\n",
        "forest_rmse"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHFKlANh30DK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "scores = cross_val_score(forest_reg, housing_prepared, housing_labels,\n",
        "                        scoring=\"neg_mean_squared_error\", cv=10)\n",
        "forest_rmse_scores = np.sqrt(-scores)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-U19cJcc0yWA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "display_scores(forest_rmse_scores)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VN_UP_IX9iSN",
        "colab_type": "text"
      },
      "source": [
        "## モデルを保存"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H15JPpFV0yTj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.externals import joblib\n",
        "\n",
        "joblib.dump(forest_reg, \"my_model.pkl\")\n",
        "# あとで次のようにしてロード\n",
        "my_model_loaded = joblib.load(\"my_model.pkl\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W1ysTwQj-p6w",
        "colab_type": "text"
      },
      "source": [
        "## グリッドサーチ"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASNsPO6V0yG0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "params_grid = [\n",
        "    {'n_estimators': [3, 10, 30], 'max_features': [2, 4, 6, 8]},\n",
        "    {'bootstrap': [False], 'n_estimators': [3, 10], 'max_features': [2, 3, 4]},\n",
        "]\n",
        "\n",
        "forest_reg = RandomForestRegressor()\n",
        "\n",
        "grid_search = GridSearchCV(forest_reg, params_grid, cv=5, scoring='neg_mean_squared_error')\n",
        "\n",
        "grid_search.fit(housing_prepared, housing_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tS5g9ESQ0yD2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "grid_search.best_params_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yOdGKCo7-7JX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "grid_search.best_estimator_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQS5dgwT-99f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cvres = grid_search.cv_results_\n",
        "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
        "    print(np.sqrt(-mean_score), params)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2oE0cEB_RV7",
        "colab_type": "text"
      },
      "source": [
        "## ランダムサーチ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EP7rJ27d_WyH",
        "colab_type": "text"
      },
      "source": [
        "## アンサンブルメソッド"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSYBzqC1_ayo",
        "colab_type": "text"
      },
      "source": [
        "## 最良のモデルと誤差の分析"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDgKu8Q8_goV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "feature_importances = grid_search.best_estimator_.feature_importances_\n",
        "feature_importances"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qj-S_S68_tJu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "extra_attribs = [\"rooms_per_hhold\", \"pop_per_hhold\", \"bedrooms_per_room\"]\n",
        "cat_encoder = cat_pipeline.named_steps[\"cat_encoder\"]\n",
        "cat_one_hot_attribs = list(cat_encoder.categories_[0])\n",
        "attributes = num_attribs + extra_attribs + cat_one_hot_attribs\n",
        "sorted(zip(feature_importances, attributes), reverse=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1wIlZKiNAmyE",
        "colab_type": "text"
      },
      "source": [
        "## テストセットでシステムを評価する"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3Ek-pn8A21f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "final_model = grid_search.best_estimator_\n",
        "\n",
        "X_test = strat_test_set.drop(\"median_house_value\", axis=1)\n",
        "y_test = strat_test_set[\"median_house_value\"].copy()\n",
        "\n",
        "X_test_prepared = full_pipeline.transform(X_test)\n",
        "\n",
        "final_predictions = final_model.predict(X_test_prepared)\n",
        "\n",
        "final_mse = mean_squared_error(y_test, final_predictions)\n",
        "final_rmse = np.sqrt(final_mse)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lcsG_rWKBfPc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "final_rmse"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_XZJ5J8Ap7C",
        "colab_type": "text"
      },
      "source": [
        "## システムを本番稼働、モニタリング、メンテナンスする"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aEGgIfsJAxDg",
        "colab_type": "text"
      },
      "source": [
        "## 試してみよう"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W9HPQklZ3ZIE",
        "colab_type": "text"
      },
      "source": [
        "# 機械学習プロジェクト　チェックリスト\n",
        "機械学習プロジェクトを行う上でのマニュアル\n",
        "\n",
        "1. 問題の枠組みを明らかにし、全体の構図をつかむ\n",
        "2. データを手に入れる\n",
        "3. データを使って洞察を得る\n",
        "4. 機械学習アルゴリズムがデータからパターンを見つけやすくなるようにデータを準備する\n",
        "5. 異なる様々なモデルを探り、最良の数個に絞り込む\n",
        "6. モデルを微調整し、それらを組み合わせて優れたソリューションにまとめる\n",
        "7. ソリューションをプレゼンテーションする\n",
        "8. システムを本番稼働、モニタリング、メンテナンスする"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WDdQJE4Z4H3-",
        "colab_type": "text"
      },
      "source": [
        "## 1. 問題の枠組みを明らかにし、全体の構図をつかむ\n",
        "\n",
        "\n",
        "1. ビジネスの用語で目標を定義する\n",
        "2. ソリューションはどのようにして使われるか\n",
        "3. 現在のソリューション/代替ソリューションはなにか\n",
        "4. この問題はどのような枠組みで処理スべきか(教師あり/教師なし, オンライン/オフライン 等)\n",
        "5. 性能をどのようにして測定すべきか\n",
        "6. その性能測定手段はビジネス目標に一致しているか\n",
        "7. ビジネス目標に到達するために必要な最小限の性能はどのようなものか\n",
        "8. 類似問題は何か。経験やツールを再利用できるか。\n",
        "9. 専門知識を持つ人はいるか\n",
        "10. 手作業で問題をどのように解決するか\n",
        "11. あなた(または他の人々)が今までに立ててきた前提条件をリストにまとめる\n",
        "12. 可能なら、前提条件をチェックする"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S9I4Onu55OML",
        "colab_type": "text"
      },
      "source": [
        "## 2. データを手に入れる\n",
        "注意: 新鮮なデータを簡単に入手できるようにするために、できる限り自動化しよう\n",
        "\n",
        "1. 必要なデータと必要度をリストにまとめる\n",
        "2. そのデータを入手できるドキュメントを見つける\n",
        "3. どれだけのスペースが必要になるかをチェックする\n",
        "4. 法的な義務をチェックし、必要なら権限を獲得する\n",
        "5. アクセス権限を獲得する\n",
        "6. 作業空間(十分な格納スペースとともに)を作る\n",
        "7. データを入手する\n",
        "8. 簡単に操作できる形式にデータを変換する\n",
        "9. 機密情報を確実に削除または保護する(例えば匿名化する)\n",
        "10. データのサイズとタイプをチェックする(時系列、サンプル、地理など)\n",
        "11. データセットを抽出して別に管理し、決して中身を見ない(カンニングはだめ)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9dJ81pwZ6OKp",
        "colab_type": "text"
      },
      "source": [
        "## 3. データを探る\n",
        "注意: このステップでは、分野の専門家の知見を取り入れるように努力しよう\n",
        "\n",
        "1. 探索のためにデータのコピーを作る(必要なら、扱えるサイズに縮小する)\n",
        "2. データ探索の記録を残すためにJupyterノートブックを作る\n",
        "3. データの属性とその特徴を調べる\n",
        "    - 名前\n",
        "    - タイプ(カテゴリ、整数/浮動小数点数, 有界/無界, テキスト, 構造化データなど)\n",
        "    - 欠損値の割合\n",
        "    - ノイズの有無とタイプ(確率的, 外れ値, 丸め誤差など)\n",
        "    - タクスにとって役立ちそうか\n",
        "    - 分布のタイプ\n",
        "4. 教師あり学習タスクの場合、ターゲット属性を明らかにする\n",
        "5. データの可視化をする\n",
        "6. 属性の相関関係を調べる\n",
        "7. マニュアルで問題を解決する方法を調べる\n",
        "8. 適用すると良さそうな変換を明らかにする\n",
        "9. 役に立ちそうな他のデータを明らかにする\n",
        "10. 学んだことをドキュメントにまとめる"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uc_n-M6q7W_W",
        "colab_type": "text"
      },
      "source": [
        "## 4. データを準備する\n",
        "注意:\n",
        "- データのコピーを使って作業しよう (オリジナルのデータセットには手をつけない)\n",
        "- すべてのデータ変換のための関数を書こう\n",
        "    - 次に新しいデータセットを入手した時にデータを簡単に準備できるようにするため\n",
        "    - 将来のプロジェクトで同じ変換をできるようにするため\n",
        "    - テストセットをクリーニング、準備するため\n",
        "    - ソリューションを稼働した時に新しいデータインスタンスをクリーニング、じゅんびするため\n",
        "    - 準備のための選択肢をハイパーパラメータとして簡単に扱えるようにするため\n",
        "\n",
        "1. データのクリーニング\n",
        "    - 外れ値を修正または除去する(オプション)\n",
        "    - 欠損値を埋める(例えば0, 平均値, 中央値などで)かその行(または列)を取り除く\n",
        "2. フィーチャーの選択(オプション)\n",
        "    - タスクのために役に立つ情報を提供しない属性を取り除く\n",
        "3. フィーチャーの操作(適宜)\n",
        "    - 連続値のフィーチャーを離散化する\n",
        "    - フィーチャーに効果が期待できる変換を加える(例えばlog(x), √x, x^2など)\n",
        "    - 複数のフィーチャーを集計したりまとめたりして効果が期待できる新フィーチャーを作る\n",
        "4. フィーチャーをスケーリングする: 標準化、正規化する"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tti0ZGDP9h96",
        "colab_type": "text"
      },
      "source": [
        "## 5. 有望なモデルを絞り込む\n",
        "注意:\n",
        "- データが膨大なものならまずまずの時間で異なる様々なモデルを訓練をできるように、小さな訓練セットを抽出するとよい。(大規模なニューラルネットやランダムフォレストなどの複雑なモデルには悪影響がおよぶので注意すること)\n",
        "- ここでも、できる限りすべてのステップを自動化するよう注意しよう\n",
        "\n",
        "1. 少々乱暴でも、様々なタイプ(線形、単純ベイズ、SVM、ランダムフォレスト、ニューラルネットなど)のモデルをすばやく訓練する\n",
        "2. 性能を測定、比較する\n",
        "    - 個々のモデルについて, N-fold cross validationを行い、N個のフォールドの平均と標準偏差を平均する\n",
        "3. 個々のアルゴリズムでもっとも重要な変数を分析する\n",
        "4. モデルが犯す誤りのタイプを分析する\n",
        "5. 簡単なフィーチャーの選択と操作を行う\n",
        "6. これらの5ステップをさらに1、2回手早く繰り返す\n",
        "7. 3種類から5種類のもっとも有望なモデルを残す。同程度のもののなかでは、異なるタイプの誤りを犯すモデルを選ぶ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RvL67c_t-Ohq",
        "colab_type": "text"
      },
      "source": [
        "## 6. システムを微調整する\n",
        "注意:\n",
        "- このステップ、特に微調整の最後の局面では、できる限り覆うのデータを使うようにしよう\n",
        "- ほかのステップと同様に、自動化できるものは自動化しよう\n",
        "\n",
        "1. 交差検証を使ってハイパーパラメータを微調整する\n",
        "    - データ変換方法、特にどうすべきかがはっきりと分からないもの(例えば、欠損値は0に置き換えるか中央値に置き換えるか、それとも行を取り除くか)はハイパーパラメータとして扱う\n",
        "    - 探らなければならないハイパーパラメータの値が非常に少ない場合を除き、グリットサーチではなくランダムサーチを行うようにする。訓練に非常に時間がかかるなら、ベイズ最適化を使ったほうが良いかもしれない(たとえば、Jasper Snoek, Hugo Larochelle, Ryan Adamsらが論じているガウス処理を使ったもの。 https://goo.gl/PEFfGr)\n",
        "2. アンサンブルメソッドを試す。最良のモデルを組み合わせると、それらを単独で実行するよりも高い性能が得られることが多い。\n",
        "3. 最終的なモデルに自身が持てたら、テストセットを対象として性能を計測し、汎化誤差を推計する\n",
        "※ 汎化誤差の測定後にはモデルに修正を加えてはならない。テストセットへの過学習に向かってどんどん進むだけになってしまう"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EyNc1At1-Nva",
        "colab_type": "text"
      },
      "source": [
        "## 7. ソリューションをプレゼンテーションする\n",
        "\n",
        "1. 今までに行ってきたことをドキュメントする\n",
        "2. すばらしいプレゼンテーションを作る\n",
        "    - まず、全体的な構図を明らかにすることを忘れないようにする\n",
        "3. ソリューションがビジネス目標を達成する理由を説明する\n",
        "4. 作業の過程で気づいた面白いポイントを紹介するのを忘れないように\n",
        "    - うまく機能したものとそうでないものを説明する\n",
        "    - 前提条件とシステムの限界をリストにまとめる\n",
        "5. 重要な発見は、見栄えの良いビジュアライゼーションか覚えやすい言葉、たとえば、【住宅価格の予測では、収入の中央値がナンバーワンの予測子です」と伝える"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-BeGgoTH-NRv",
        "colab_type": "text"
      },
      "source": [
        "## 8. 本番稼働\n",
        "\n",
        "1. ソリューションを本番稼働できる状態にする(本番データの入力を受け付けられるようにしたり、ユニットテストを書いたりすることなど)\n",
        "2. 定期的にシステムの性能をチェックし、性能が落ちたらアラートを生成するモニタリングコードを書く\n",
        "    - 緩やかな性能の降下に注意する。モデルはデータの発展とともに「腐って」いくことが多い\n",
        "    - 性能の測定は、人間の関与を必要とすることがある(たとえば、クラウドソーシングサービスを介したもの)\n",
        "    - 入力の品質もモニタリングすること(たとえば、故障したセンサーがでたらめな値を送っていないか、ほかのチームの出力が陳腐化していないか)。オンライン学習システムではこれが特に重要になる\n",
        "3. 新しいデータで定期的にモデルを訓練し直す(できる限り自動化する)"
      ]
    }
  ]
}